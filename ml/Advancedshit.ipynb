{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, LSTM, Input\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96 entries, 0 to 95\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  96 non-null     object\n",
      " 1   Resume    96 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#ATS System\n",
    "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
    "df.head()\n",
    "df.info()\n",
    "max_len = 300\n",
    "resumes = df['Resume']\n",
    "categories = df['Category']\n",
    "Tokenizer = Tokenizer()\n",
    "Tokenizer.fit_on_texts(resumes)\n",
    "sequences = Tokenizer.texts_to_sequences(df['Resume'].values)\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "y = pd.get_dummies(df['Category']).values\n",
    "\n",
    "label_encoder = LabelEncoder()  # Use LabelEncoder for string categories\n",
    "categories_encoded = label_encoder.fit_transform(categories)\n",
    "categories_encoded = to_categorical(categories_encoded)  # One-hot encode for multi-class classification\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dim = 100\n",
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((len(Tokenizer.word_index) + 1, embeddings_dim))\n",
    "for word, i in Tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "input_layer = Input(shape=(max_len,))\n",
    "\n",
    "# Embedding layer\n",
    "embedding_layer = Embedding(len(Tokenizer.word_index) + 1, embeddings_dim, input_length=max_len, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "\n",
    "# LSTM layer\n",
    "lstm_layer = LSTM(units=128, return_sequences=True)(embedding_layer)\n",
    "\n",
    "# MultiHeadAttention layer\n",
    "attention_layer = MultiHeadAttention(num_heads=2, key_dim=2)(lstm_layer, lstm_layer)\n",
    "\n",
    "# Second LSTM layer\n",
    "lstm_layer_2 = LSTM(units=64)(attention_layer)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(7, activation='softmax')(lstm_layer_2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\karan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\karan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2/2 [==============================] - 4s 782ms/step - loss: 1.9469 - accuracy: 0.0395 - val_loss: 1.9433 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 264ms/step - loss: 1.9379 - accuracy: 0.1974 - val_loss: 1.9543 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 256ms/step - loss: 1.9280 - accuracy: 0.1974 - val_loss: 1.9690 - val_accuracy: 0.1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9690 - accuracy: 0.1000\n",
      "Loss: 1.9690393209457397\n",
      "1/1 [==============================] - 0s 496ms/step\n",
      "Predicted category: DevOps\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=[EarlyStopping(patience=2)])\n",
    "loss,auc = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss}\")\n",
    "\n",
    "new_resume = \"I am a software engineer with 5 years of experience in Java, Python, and C++. I have a Bachelor's degree in Computer Science from MIT.\"\n",
    "new_resume = Tokenizer.texts_to_sequences([new_resume])\n",
    "new_resume = pad_sequences(new_resume, maxlen=max_len)\n",
    "prediction = model.predict(new_resume)\n",
    "print(f\"Predicted category: {categories[np.argmax(prediction)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
