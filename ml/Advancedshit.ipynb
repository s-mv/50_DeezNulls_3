{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 14:13:57.807821: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-24 14:13:58.038146: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-24 14:13:58.038296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-24 14:13:58.079399: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-24 14:13:58.166794: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-24 14:13:58.168165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-24 14:13:59.879283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, LSTM, Input\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96 entries, 0 to 95\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  96 non-null     object\n",
      " 1   Resume    96 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
    "df.head()\n",
    "df.info()\n",
    "max_len = 3000\n",
    "resumes = df['Resume']\n",
    "categories = df['Category']\n",
    "Tokenizer = Tokenizer()\n",
    "Tokenizer.fit_on_texts(resumes)\n",
    "sequences = Tokenizer.texts_to_sequences(df['Resume'].values)\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "y = pd.get_dummies(df['Category']).values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "categories_encoded = label_encoder.fit_transform(categories)\n",
    "categories_encoded = to_categorical(categories_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dim = 100\n",
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((len(Tokenizer.word_index) + 1, embeddings_dim))\n",
    "for word, i in Tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "input_layer = Input(shape=(max_len,))\n",
    "\n",
    "embedding_layer = Embedding(len(Tokenizer.word_index) + 1, embeddings_dim, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "lstm_layer = LSTM(units=128, return_sequences=True)(embedding_layer)\n",
    "attention_layer = MultiHeadAttention(num_heads=2, key_dim=2)(lstm_layer, lstm_layer)\n",
    "lstm_layer_2 = LSTM(units=64)(attention_layer)\n",
    "\n",
    "output_layer = Dense(7, activation='softmax')(lstm_layer_2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 14:14:19.441220: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5472000000 exceeds 10% of free system memory.\n",
      "2024-03-24 14:14:26.755172: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5472000000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=2097152, callbacks=[EarlyStopping(patience=2)])\n",
    "loss, auc = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss}\")\n",
    "\n",
    "new_resume = \"\"\"\n",
    "KUSHL ALVE  Work Experience :  ●   Web Developer Intern (at Prodigy InfoTech, Mumbai) :   Nov,2023 - Dec,2023  Developed following web applications using HTML, CSS and JS :  1.   Responsive Landing Page.  2.   Stopwatch web application.  3.   Tic-Tac-Toe Application.  4.   Personal Portfolio Website.  Education :  ●   BE Computer Engineering (2022-2026) :  Vivekanand Education Society’s Institute of Technology, Chembur.  Technical Skills :  ●   React.js , Node.js, Express.js  ●   HTML, CSS, JavaScript  ●   PostgreSQL  ●   Python  Projects :  ●   Intelligent Scholarship Portal :  →   used React.js, Node.js, Express.js and PostgreSQL.  → This project aims at providing all scholarships including private ones in the  existing National Scholarship Portal to help save students’ time.  ●   Movie Rating System :  → used Java.  → This project collected various users’ ratings for movies.  Certifications and Achievements :  ●   The Complete Full Stack Web Development Bootcamp 2024 course - Angela Yu  ●   Syrus Hackathon 23’  ●   Received LOR(Letter of Recommendation) from Prodigy InfoTech.  ●   Google Cloud Computing Foundations Skill Badge.  Contact :  ●   +91 9967457425 (mobile)  ●   https://www.linkedin.com/in/kushl-alve-2627541b0/ (LinkedIn)  ●   https://github.com/moodyspider266 (GitHub)  ●   kushlalve007@gmail.com / 2022.kushl.alve@ves.ac.in (Email) \n",
    "\"\"\"\n",
    "new_resume = Tokenizer.texts_to_sequences([new_resume])\n",
    "new_resume = pad_sequences(new_resume, maxlen=max_len)\n",
    "prediction = model.predict(new_resume)\n",
    "print(f\"Predicted category: {categories[np.argmax(prediction)]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
